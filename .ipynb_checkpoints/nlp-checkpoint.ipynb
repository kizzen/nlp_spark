{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection Using Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark is a widely used open-source data processing framework which allows you to distribute your compute power across many servers in lieu of your local machine. It uses Resilient Distributed Datasets (RDDs) as it's foundational data structure. RDDs are a distributed collection of objects which can be divided into logical partitions operated on in parallel across a cluster of computers. Here are some key features of RDDs:\n",
    "\n",
    "1. Resilience: RDDs can recover lost data caused by the failure of a node. This is also called fault tolerance.\n",
    "2. Distributed: data present in an RDD resides on multiple nodes of a cluster.\n",
    "3. Lazy evaluation: transformations are performed on data on an as-needed basis.\n",
    "4. Immutability: data stored in an RDD is in the read-only mode and is unchangeable over time.\n",
    "5. In-memory: it is possible to store data in an RDDs and perform in-memory computation on the data.\n",
    "6. Partitioning: data in RDDs can be grouped into logical parts, called partitions. Data transformations can be applied on these partitions. \n",
    "\n",
    "Spark provides a high-level API for Python, i.e. pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/khalilezzine/opt/anaconda3/lib/python3.7/site-packages (2.4.5)\n",
      "Requirement already satisfied: py4j==0.10.7 in /Users/khalilezzine/opt/anaconda3/lib/python3.7/site-packages (from pyspark) (0.10.7)\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.4.5\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.11.12, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_121\n",
      "Branch HEAD\n",
      "Compiled by user centos on 2020-02-02T19:38:06Z\n",
      "Revision cee4ecbb16917fa85f02c635925e2687400aa56b\n",
      "Url https://gitbox.apache.org/repos/asf/spark.git\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "from pyspark import SparkContext\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "!spark-submit --version\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from pyspark.mllib.feature import IDF, Normalizer\n",
    "from pyspark.mllib.classification import (NaiveBayes, LogisticRegressionWithLBFGS, SVMWithSGD) \n",
    "import numpy\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from time import time\n",
    "from pyspark.sql import DataFrame\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural language processing (NLP) is the application of machine learning algorithms to teach computers how to understand human language. This project will build and evaluate NLP models that classify email messages as spam or non-spam. A Spark data pipeline will be used to train and evaluate these spam classifiers. Python's Natural Language Toolkit (NLTK) will be used to perform some of the data processing steps. \n",
    "\n",
    "Machine learning models cannot make predictions using raw text alone - they require numerical values to perform the training computations. In this report, we will use a method called Term Frequency Inverse Data Frequency (TF-IDF) to convert text to numbers for our NLP models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the lingspam dataset in this project to build the spam classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the ling_spam dataset, this can take a moment.\n",
      ">>> Unzipping finished.\n"
     ]
    }
   ],
   "source": [
    "os.chdir('datasets/')\n",
    "print(\"Extracting the ling_spam dataset, this can take a moment.\")\n",
    "!tar -xf lingspam_public02.tar.gz\n",
    "print(\">>> Unzipping finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After unzipping the files, you will notice that there are 4 sub-directories corresponding to the 4 versions of the corpus:\n",
    "1. bare: lemmatiser disabled, stop-list disabled.\n",
    "2. lemm: lemmatiser enabled, stop-list disabled.\n",
    "3. lemm_stop: lemmatiser enabled, stop-list enabled.\n",
    "4. stop: lemmatiser disabled, stop-list enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each one of these 4 directories contain 10 sub-directories (part1, \n",
    "..., part10). These correspond to the 10 partitions of the corpus \n",
    "that were used in the 10-fold experiments. In each repetition, one \n",
    "part was reserved for testing and the other 9 were used for training. \n",
    "\n",
    "Each one of the 10 subdirectories contain both spam and legitimate \n",
    "messages, one message in each file. Files whose names have the form\n",
    "spmsg*.txt are spam messages. All other files are legitimate messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Definitions</u>\n",
    " - corpus: a collection of texts\n",
    " - lemmatization: the grouping of words that share the same structure but are spelled differently, e.g. \"organize, organizes, organizing\"\n",
    " - stop list: list of stop words, which are commonly used words that are filtered out for text processing given their lack of predictive power, e.g. \"a,\" \"and,\" \"but,\" \"how,\" \"or,\" and \"what\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset and create RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been loaded, the first step is to read the dataset and create RDDs. To do so, a Spark context must be created, which represents the connection to a Spark cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps to create the RDDs are:\n",
    "1. Start by reading the directory with text files from the file system (\"datasets/bare\"). Load all text files per directory (part1, part2, ... , part10) using `wholeTextFiles()`, which creates one RDD per part, containing tuples (filename, text). This is a good choice as the text files are small.\n",
    "2. We will use one of the RDDs as test set, the rest as training set. For the training set you need to create the union of the remaining RDDs.\n",
    "3. Remove the path and extension from the filename using the regular expression provided in the code snippet below.\n",
    "\n",
    "The training set labels are \"spam\" is the file name starts with \"spmsg\" and \"non-spam\" otherwise. \n",
    "\n",
    "We will put the code in each cell into a function that we can reuse later. In this way we can develop the whole preprocessing with the smaller test set and apply it to the training set once we know that everything works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTestTrainRDDs(pathString):\n",
    "    ''' Takes one of the four subdirectories of the lingspam dataset and returns two RDDs one each for testing \n",
    "        and training. We should see 10 parts that we can use for creating train and test sets.\n",
    "    '''\n",
    "    p = Path(pathString) # gets a path object representing the current directory path.\n",
    "    dirs = list(p.iterdir()) # get the directories part1 ... part10. \n",
    "    dirs = [str(dir.absolute()) for dir in dirs]\n",
    "    rddList = [] # create a list for the RDDs\n",
    "    for d in dirs: # iterate through the directories\n",
    "        rdd = sc.wholeTextFiles(d)\n",
    "        rddList.append(rdd)\n",
    "\n",
    "    testRDD1 = rddList[9] # set the test set\n",
    "    trainRDD1 = rddList[0] # start the training set from 0 and \n",
    "    for i in range(1,9):\n",
    "        trainRDD1 = trainRDD1.union(rddList[i]) # create a union of the current and the next\n",
    "        testRDD2 = testRDD1.map(lambda x : (re.split('[/\\.]', x[0])[-2],x[1]))\n",
    "        trainRDD2 = trainRDD1.map(lambda x : (re.split('[/\\.]', x[0])[-2],x[1]))\n",
    "    return (trainRDD2,testRDD2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print out the number of test and train RDDs that we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testRDD.count():  1734\n",
      "trainRDD.count():  15158 \n",
      "\n",
      "Example RDD: \n",
      " [('spmsgc104 3', 'Subject: free y2k fix ! ! ! < > . : adv \" \" . ,\\n\\nthe good news is : that you can now test your computer for full y2k compliance ( both bios and real time clocks ) and even correct it with a simple , inexpensive download . the great news is : we offer a free test & evaluation period while you decide whether you want to purchase this solution . no one else offers the comprehensive guarantee that we have for you . for additional information on our free evaluation period , reply to : y2kfreetest @ popmail . com type y2k on the subject line * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * to be removed from this mailing list reply to : resource22 @ popmail . com , type remove on subject line . thank you * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\\n')]\n"
     ]
    }
   ],
   "source": [
    "trainRDD_testRDD = makeTestTrainRDDs('lingspam_public/bare') # read from the 'bare' directory - takes a bit of time\n",
    "(trainRDD,testRDD) = trainRDD_testRDD # unpack the returned tuple\n",
    "print('testRDD.count(): ',testRDD.count()) # count of RDDs in the test set\n",
    "print('trainRDD.count(): ',trainRDD.count(),'\\n') # count of RDDs in the training set\n",
    "print('Example RDD: \\n',testRDD.take(1)) # should be (filename,[tokens]) \n",
    "rdd1 = testRDD # use this for development in the next tasks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `take()` method for the RDD shows us that each email can be thought of to have a key-value pair structure where:\n",
    "- the key is the email ID, e.g. \"8-1041msg1 2\", including if it's spam or not (\"spmsg\" or \"msg\")\n",
    "- the value is the email itself, including the subject and body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and remove punctuation\n",
    "\n",
    "Now we need to split the words, a process called *tokenization* by linguists, and remove punctuation. We will use the Python [Natural Language Toolkit](http://www.nltk.org) *NLTK* to do the tokenization. We use the NLTK function `word_tokenize`. Then we will remove punctuation. There is no specific function for this, so we use a regular expression in a list comprehension. \n",
    "\n",
    "We use a new technique here: we separate keys and values of the RDD, using the RDD functions `keys()` and `values()`, which yield each a new RDD. Then we process the values and *zip* them together with the keys again. We wrap the whole sequence into one function `prepareTokenRDD` for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    ''' Apply the nltk.word_tokenize() method to our text, return the token list. \n",
    "        It is important that this is done here in the function, as it needs to be done on every worker.\n",
    "        If we do the download outside a this function, it would only be executed on the driver \n",
    "    '''\n",
    "    nltk.download('punkt') # this loads the standard NLTK tokenizer model er     \n",
    "    return nltk.word_tokenize(text)\n",
    "    \n",
    "def removePunctuation(tokens):\n",
    "    ''' Remove punctuation characters from all tokens in a provided list. \n",
    "        This will remove all punctiation from string\n",
    "    '''\n",
    "    tokens2 = [re.sub('[()\\[\\],.?!\";_]','',i) for i in tokens ]\n",
    "    return tokens2\n",
    "\n",
    "def prepareTokenRDD(fn_txt_RDD):\n",
    "    ''' Take an RDD with (filename,text) elements and transform it into a (filename,[token ...]) \n",
    "        RDD without punctuation characters.  We zip the two RDDs together i.e. produce tuples with one item\n",
    "        from each RDD. This works because we have only applied mappings to the values, therefore the items in both \n",
    "        RDDs are still aligned.\n",
    "    '''\n",
    "    rdd_vals2 = fn_txt_RDD.values() # it's convenient to process only the values. \n",
    "    rdd_vals3 = rdd_vals2.map(tokenize) # create a tokenised version of the values by mapping\n",
    "    rdd_vals4 = rdd_vals3.map(removePunctuation) # remove punctuation from the values\n",
    "    rdd4 = fn_txt_RDD.keys().zip(rdd_vals4) # zip RDDs together\n",
    "    rdd5 = rdd4.map(lambda x: (x[0],[i for i in x[1] if len(i)!=0]))    \n",
    "    rdd6 = rdd5.filter(lambda x: len(x[1])!=0) # remove items without tokens using RDD.filter and a lambda. \n",
    "    return rdd6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By printing a resulting RDD, we now see that the email has been tokenized: each word or punctuation mark is a single string item (token) in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spmsgc104 3', ['Subject', ':', 'free', 'y2k', 'fix', '<', '>', ':', 'adv', '``', '``', 'the', 'good', 'news', 'is', ':', 'that', 'you', 'can', 'now', 'test', 'your', 'computer', 'for', 'full', 'y2k', 'compliance', 'both', 'bios', 'and', 'real', 'time', 'clocks', 'and', 'even', 'correct', 'it', 'with', 'a', 'simple', 'inexpensive', 'download', 'the', 'great', 'news', 'is', ':', 'we', 'offer', 'a', 'free', 'test', '&', 'evaluation', 'period', 'while', 'you', 'decide', 'whether', 'you', 'want', 'to', 'purchase', 'this', 'solution', 'no', 'one', 'else', 'offers', 'the', 'comprehensive', 'guarantee', 'that', 'we', 'have', 'for', 'you', 'for', 'additional', 'information', 'on', 'our', 'free', 'evaluation', 'period', 'reply', 'to', ':', 'y2kfreetest', '@', 'popmail', 'com', 'type', 'y2k', 'on', 'the', 'subject', 'line', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'to', 'be', 'removed', 'from', 'this', 'mailing', 'list', 'reply', 'to', ':', 'resource22', '@', 'popmail', 'com', 'type', 'remove', 'on', 'subject', 'line', 'thank', 'you', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*'])\n"
     ]
    }
   ],
   "source": [
    "rdd2 = prepareTokenRDD(rdd1) # Use the test set for now, because it is smaller\n",
    "print(rdd2.take(1)[0]) # for checking result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating normalised TF.IDF vectors of defined dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The hashing trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emails in the corpus have different lengths hence the training word vectors will vary as well. The hashing function maps data of arbitrary size to a fixed size. Using the hashing trick, each email, no matter the size, will be transformed into a fixed length numerical vector. All hashing functions share the following properties:\n",
    " - the hashing function will always produce the same output if given the same input\n",
    " - the choice of the hashing function will determine the range of the outputs, e.g. one hashing function might return values which can only fall in the 0-1024 range\n",
    " - hashing functions are one-way (input to output) hence you cannot reverse engineer the hashing function to determine the input given the output\n",
    " - hashing functions might output the same values for multiple inputs (collision)\n",
    " \n",
    "We create a function called `hashing_vectorize` using the built-in `hash` method to transform all emails into vectors of fixed length `N`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the hashing trick to create a fixed-size vector from a word list\n",
    "def hashing_vectorize(text,N): # arguments: the list and the size of the output vector\n",
    "    v = [0] * N  # create vector of 0s\n",
    "    for word in text: # iterate through the words \n",
    "        h = hash(word)# get the hash value\n",
    "        v[h%N] += 1 # add 1 at the hashed address\n",
    "    return v # return hashed word vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF is a measure that determines how specific a word is within a document. For example, if a word appears many times in a document (term frequency) but does not appear frequently in other documents, then it will have a high TF-IDF score. Common words which are used frequently across multiple documents, or in this case emails, will have a low TF-IDF score. It is calculated my multiplying the following terms together:\n",
    " - term frequency (TF): number of times a word appears in the email\n",
    " - inverse document frequency (IDF): calculated by taking the logarithm of the total number of emails divided by the number of emails that contain a specific word\n",
    "\n",
    "We use the TF-IDF values to populated our fixed length hashing vectors by creating a TF-IDF object (`IDF()`) and normalizing the results (`Normalizer()) between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normTFIDF(fn_tokens_RDD, vecDim, caching=True):\n",
    "    keysRDD = fn_tokens_RDD.keys()\n",
    "    tokensRDD = fn_tokens_RDD.values()\n",
    "    tfVecRDD = tokensRDD.map(lambda tokens: hashing_vectorize(tokens,vecDim))\n",
    "\n",
    "    idf = IDF() # create IDF object\n",
    "    idfModel = idf.fit(tfVecRDD) # calculate IDF values\n",
    "    tfIdfRDD = idfModel.transform(tfVecRDD)\n",
    "    # create a Normalizer object like in the example linked above\n",
    "    norm = Normalizer() # create a Normalizer object like in the example linked above\n",
    "    # apply Normalizer to the tfIdfRDD\n",
    "    normTfIdfRDD = norm.transform(tfIdfRDD) # and apply it to the tfIdfRDD\n",
    "    # zip the keys and values together\n",
    "    zippedRDD = keysRDD.zip(normTfIdfRDD) # zip the keys and values together\n",
    "    return zippedRDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each email, we now have a tuple consisting of the filename (including the spam classification) as well as a fixed length numerical vector which can be used for model training. We print out one of these vectors below, in the case where the length N is equal to 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spmsgc104 3', DenseVector([0.9896, 0.0324, 0.0255, 0.0, 0.0, 0.0974, 0.0465, 0.037, 0.0767, 0.0]))]\n"
     ]
    }
   ],
   "source": [
    "testDim = 10 # too small for good accuracy, but OK for testing\n",
    "rdd3 = normTFIDF(rdd2, testDim, True) # test our\n",
    "print(rdd3.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side experiment: measure the impact of caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `normTFIDF` lets us switch caching on or off. We measure the effect of caching by noting the time for both options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating TF.IDF vectors, 3 trials \n",
      " Mean time with caching:  71.48 seconds \n",
      " Mean time without caching:  69.59 seconds\n"
     ]
    }
   ],
   "source": [
    "# run a small experiment with caching set to True or False, 3 times each\n",
    "resCaching = [] # for storing results\n",
    "resNoCache = [] # for storing results\n",
    "for i in range(3): # 3 samples\n",
    "    # start timer\n",
    "    startTime = time()\n",
    "    testRDD1 = normTFIDF(rdd2, testDim, True) # \n",
    "    # call an action on the RDD to force execution\n",
    "    testRDD1.collect()\n",
    "    # end timer\n",
    "    endTime = time()\n",
    "    resCaching.append( endTime - startTime ) # calculate the difference\n",
    "    \n",
    "    # start timer\n",
    "    startTime = time()\n",
    "    testRDD2 = normTFIDF(rdd2, testDim, False) \n",
    "    # call an action to force execution   \n",
    "    testRDD2.collect()\n",
    "    # end timer\n",
    "    endTime = time()\n",
    "    resNoCache.append(endTime - startTime)\n",
    "\n",
    "# calculate average times\n",
    "meanTimeCaching = round(sum(resCaching)/len(resCaching),2)\n",
    "meanTimeNoCache = round(sum(resNoCache)/len(resCaching),2)\n",
    "\n",
    "print(' Creating TF.IDF vectors, 3 trials \\n Mean time with caching: ',\n",
    "      meanTimeCaching, 'seconds \\n Mean time without caching: ',\n",
    "      meanTimeNoCache,'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for this particular output show that caching is faster than non-caching. \n",
    "\n",
    "We are calculating wall clock time here (i.e. latency). The results will be noisy, especially for short running jobs such as this one. However, when we run the cell multiple times we consistently see that caching is the faster option.\n",
    "\n",
    "Usually, the work law states that, given n the number of processors, multiplying n by the time it takes to run the task on n processors has to be greater than the time it takes to run a task on a single processor. However, in practice this might sometimes not be the case and the reason for this is memory hierarchy: if the partitioned data is small enough to fit into memory, then it could be faster than running it on one machine that is reading and writing from disk.  \n",
    "\n",
    "In addition, non-caching executes different data pipelines independently, whereas these processes can be shared using caching, thus taking less time.\n",
    "\n",
    "Finally, caching is faster because the RDD is re-used multiple times within the foor loop. The data is cached during the first action call (`.count`). All of the repeat actions will find the RDD blocks in memory. With caching not enabled this is not the case and the task takes longer since spark evaluates lazily and the RDD must be re-evaluated in full each time an action is called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LabeledPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a function that transforms the labels (current example: \"8-1041msg1 2\") into labels representing a binary classification: 1 if email is spam, 0 otherwise. We use the `RDD.map()` to create an RDD of LabeledPoint objects `LabeledPoint()`. An example LabelPoints for a non-spam email is printed\n",
    "below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(1.0, [0.9896457148958359,0.03241063850896587,0.025465501685616038,0.0,0.0,0.09740091687861234,0.04654346854229574,0.03704072972453242,0.07666269622432531,0.0])]\n"
     ]
    }
   ],
   "source": [
    "# create labelled points of vector size N out of an RDD with normalised (filename [(word,count), ...]) items\n",
    "def makeLabeledPoints(fn_vec_RDD): # RDD and N needed \n",
    "    # we determine the true class as encoded in the filename and represent as 1 (spam) or 0 (good)\n",
    "    # use a conditional expression to get the class label (True or False)\n",
    "    cls_vec_RDD = fn_vec_RDD.map(lambda x: (1 if x[0].startswith('sp') else 0,x[1]) )\n",
    "    # now we can create the LabeledPoint objects with (class,vector) arguments\n",
    "    lp_RDD = cls_vec_RDD.map(lambda cls_vec: LabeledPoint(cls_vec[0],cls_vec[1]))\n",
    "    return lp_RDD \n",
    "\n",
    "# for testing\n",
    "testLpRDD = makeLabeledPoints(rdd3) \n",
    "print(testLpRDD.take(1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate data processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be useful to have a single function (`loadAndPreprocess`) that consolidates all the data processing steps. We can tune the parameter N, the vector size, to improve the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(1.0, [0.006820394456764202,0.005252299608125127,0.0,0.00994561206584296,0.0,0.02268149523518462,0.03397488030802731,0.0,0.0,0.0,0.023863445974781305,0.0,0.0,0.0,0.0,0.013913161502230941,0.0,0.009018001325248876,0.0,0.014461444011701827,0.0,0.041181949816747124,0.03544340052598322,0.0,0.014641487650620656,0.014295504642136034,0.0,0.01491841809876444,0.0,0.0,0.05996516094359604,0.0,0.0,0.0,0.0,0.0,0.011655772207896209,0.03449360524237956,0.016800685414711972,0.0,0.9834505093182238,0.0,0.018732126345668537,0.0,0.0,0.0,0.0,0.019027337709104277,0.04764922235122011,0.012620085552194394,0.020828081825915,0.012783696736923226,0.0,0.0,0.019521069009794875,0.033423954935694174,0.020828081825915,0.0,0.04544159896117538,0.012948157118455345,0.0,0.024808190611971637,0.012295376008186124,0.0,0.00907289874653656,0.01535817947925166,0.0,0.0,0.031046686299388535,0.01814579749307312,0.011240723722172382,0.019921313855009025,0.0455029512226766,0.0026261498040625634,0.0,0.0551340482557182,0.0,0.012296213904851834,0.0,0.016246936056648276,0.0,0.0,0.02963181246509851,0.0,0.011655772207896209,0.016246936056648276,0.0,0.0,0.0378362933445192,0.00767908973962583,0.0,0.036263383030747755,0.0,0.0,0.0,0.014152332927854998,0.0,0.016246936056648276,0.010874006508337163,0.01134074761759231])]\n"
     ]
    }
   ],
   "source": [
    "# now we can apply the preprocessing chain to the loaded data  \n",
    "# N is for controlling the vector size\n",
    "def preprocess(rawRDD,N):\n",
    "    \"\"\" take a (filename,text) RDD and transform into LabelledPoint objects \n",
    "        with class labels and a TF.IDF vector with N dimensions. \n",
    "    \"\"\"\n",
    "    tokenRDD = prepareTokenRDD(rawRDD) \n",
    "    tfIdfRDD = normTFIDF(tokenRDD,N) \n",
    "    lpRDD = makeLabeledPoints(tfIdfRDD) \n",
    "    return lpRDD # return RDD with LabeledPoints\n",
    "\n",
    "# and with this we can start the whole process from a directory, N is again the vector size\n",
    "def loadAndPreprocess(directory,N):\n",
    "    \"\"\" load lingspam data from a directory and create a training and test set of preprocessed data \"\"\"\n",
    "    # read from the directory using the function created \n",
    "    trainRDD_testRDD = makeTestTrainRDDs(directory)\n",
    "    # unpack the returned tuple\n",
    "    (trainRDD,testRDD) = trainRDD_testRDD\n",
    "    return (preprocess(trainRDD,N),preprocess(testRDD,N)) # apply the preprocessing function defined above\n",
    "\n",
    "# prepare the training data\n",
    "trainLpRDD = preprocess(trainRDD,testDim) \n",
    "# let's re-run with another vector size\n",
    "train_test_LpRDD = loadAndPreprocess('lingspam_public/lemm',100) \n",
    "(trainLpRDD,testLpRDD) = train_test_LpRDD \n",
    "print(testLpRDD.take(1)) # print test RDD example for N=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train some classifiers: LR, NB and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `LabelPoint()` object to train the following classifiers: Logistic Regression (LR), Naive Bayes (NB) and Support Vector Machine (SVM). We calculate the accuracy of the model on the training set. LR is the best performing model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR \n",
      "--\n",
      "Accuracy 96.9% (data items: 15623, correct: 15143)\n",
      "\n",
      "NB \n",
      "--\n",
      "Accuracy 83.4% (data items: 15623, correct: 13025)\n",
      "\n",
      "SVM \n",
      "---\n",
      "Accuracy 83.4% (data items: 15623, correct: 13025)\n",
      "\n",
      "LR is the best performing model.\n"
     ]
    }
   ],
   "source": [
    "## train the model with an (f,[(w,c), ...]) RDD. This is practical as we can reuse the function for TF.IDF\n",
    "def trainModel(lpRDD):\n",
    "    '''\n",
    "       Train 3 classifier models on the given RDD with LabeledPoint objects.\n",
    "       A list of trained model is returned.\n",
    "    '''\n",
    "    # LR - this is the best model\n",
    "    model1 = LogisticRegressionWithLBFGS.train(lpRDD) \n",
    "    \n",
    "    # NB - doesn't work well\n",
    "    model2 = NaiveBayes.train(lpRDD) #\n",
    "\n",
    "    # SVM - doesn't work well\n",
    "    model3 = SVMWithSGD.train(lpRDD) \n",
    "    return [model1,model2,model3]\n",
    "\n",
    "def testModel(model, lpRDD):\n",
    "    '''Tests the classification accuracy of the given model on the given RDD with LabeledPoint objects. '''\n",
    "    # make prediction and evaluate training set accuracy\n",
    "    # get the prediction and ground truth (label) for each item.\n",
    "    predictionAndLabel = lpRDD.map(lambda p: (model.predict(p.features), p.label)) \n",
    "    \n",
    "    # count the correct predictions \n",
    "    correct = predictionAndLabel.filter(lambda xv: xv[0] == xv[1]).count() \n",
    "\n",
    "    # and calculate the accuracy \n",
    "    accuracy = correct/lpRDD.count()\n",
    "    print('Accuracy {:.1%} (data items: {}, correct: {})'.format(accuracy,lpRDD.count(), correct)) \n",
    "    return accuracy # and return the value  \n",
    "\n",
    "models = trainModel(trainLpRDD) # just for testing\n",
    "print('\\nLR \\n--')\n",
    "testModel(models[0], trainLpRDD) # just for testing\n",
    "print('\\nNB \\n--')\n",
    "testModel(models[1], trainLpRDD) # just for testing\n",
    "print('\\nSVM \\n---')\n",
    "testModel(models[2], trainLpRDD) # just for testing\n",
    "print('\\nLR is the best performing model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now automate the whole process from reading the files, through preprocessing, and training up to evaluating the models. In the end we have a single function that takes all the parameters we are interested in and produces trained models and an evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 83.4% (data items: 15623, correct: 13037)\n",
      "Accuracy 67.1% (data items: 1734, correct: 1164)\n",
      "Accuracy 83.4% (data items: 15623, correct: 13025)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "Accuracy 83.4% (data items: 15623, correct: 13025)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.8344748127760353, 0.8337067144594508, 0.8337067144594508],\n",
       " [0.671280276816609, 0.8339100346020761, 0.8339100346020761]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this method should take RDDs with (f,[(w,c), ...])\n",
    "def trainTestModel(trainRDD,testRDD):\n",
    "    '''\n",
    "        Trains 3 models and tests them on training and test data.\n",
    "        Returns a matrix the training and testing (rows) accuracy values for all models (columns). \n",
    "    ''' \n",
    "    # train models on the training set\n",
    "    models = trainModel(trainRDD)\n",
    "    results = [[],[]] # matrix for 2 modes (training/test) vs n models (currently 3) \n",
    "    for mdl in models:\n",
    "        results[0].append(testModel(mdl,trainRDD))\n",
    "        results[1].append(testModel(mdl,testRDD))\n",
    "    return results\n",
    "\n",
    "def trainTestFolder(folder,N):\n",
    "    '''\n",
    "        Reads data from a folder, preproceses the data, and trains and evaluates models on it.\n",
    "    '''\n",
    "    train_test_LpRDD = loadAndPreprocess(folder,N) # create the RDDs\n",
    "    (trainLpRDD,testLpRDD) = train_test_LpRDD # unpack the RDDs \n",
    "    return trainTestModel(trainLpRDD,testLpRDD) # train and test\n",
    "\n",
    "trainTestFolder('lingspam_public/lemm',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a single function that allows us to vary the vector size easily. We will run experiments to test vector sizes 3, 30, 300, 3000 and examine the effect on the classification accuracy.\n",
    "\n",
    "We can use the function `trainTestFolder` to test different data types. The dataset has raw text in folder `bare`, lemmatised text in  `lemm` (similar to stemming, reduces to basic word forms), `stop` (with stopwords removed), and `lemm_stop` (lemmatised and stopwords removed). We can also test how the classification accuracy differs for these four data types. The results can be collected in a data structure that can be saved for future analysis. The results of the experiments are found in the Appendix at the end of this report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance when varying vector size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the size of the density vectors improves the train and test accuracy for the LR and NB classifiers. At smaller vector sizes, we have more collisions, i.e., the tokens (words) are  more often mapped to the same indices. When several collisions occur, the vector value for an index goes to 0 based on the formula log(N/dfi). At these smaller vector sizes we also see comparable results for the 3 classifiers and there is no overfitting. As the  vector size increases, this minimizes the number of collisions.\n",
    "\n",
    "Using LR, if the vector size is large enough (over 300) then each word can be mapped to an index without any collisions, the training accuracy goes to 100% and there is overfitting on the data. Naive Bayes test accuracy increases up to a vector size of 3000 but collapses at the higher value. This is because Vector length of 30,000 is larger than the  average vector length of emails in the 'bare' corpus, as well as the assumption of independence inherent in NB is not correct for this dataset.\n",
    "\n",
    "The effects of varying the vector size does not have an effect on the  accuracy of the SVM, which stays constant at 83.4% (train) and 83.2%(test). SVM is also the worst performing model compared to LR and NB. SVM models attempt to minimise overall error and tend to perform poorly on the minority class in unbalanced problems (spam classification is typically highly unbalanced)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on different data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that for LR the train and test accuracy remain constant for the different data types (bare, stop, lemm and lemm stop) at 100% (train) and 97.6% (test). It achieved the best results compared to the two other models. SVM also shows similar results (83.4% for training and 83.2% for testing) regardless if the words are transformed or not, via lemmatization, stop or a combination of the two. Hence these three transformations do not have any increased benefit over taking the bare corpus. It is possible that the reason for this lies with the hashing itself, and that the output from hashing and the resulting dimensionality reduction is not affected by lemm or stop (and lemm and stop reduce dimensionality as well). One way to test this hypothesis is to perform this experiment without hashing; however, this would be impractical and too computationally expensive. Hence lemm and stop are good preprocessing steps to take in spam filtering, since they can reduce the dataset without reducing the accuracy of both SVM and LR, which are discriminative models. \n",
    "\n",
    "In reducing order of accuracy, NB, a generative model, performs best on Bare followed by lem, stop and lemm stop. However, NB is also a low-bias high variance model, and the variation in the results in not great enough to suggest that lemm and stop have a big effect on accuracy. Hence it is recommended that these pre-processing steps are still performed when using NB, as like mentioned before they reduce the dimensionality and the size of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best strategy to increase writing speed while maintaining quality is twofold:\n",
    "1. Write a bad first draft and do so as quickly as possible - do not overthink and worry about writing quality.\n",
    "2. Be ruthless in editing what you just wrote.\n",
    "\n",
    "After completing this NLP project and learning about stemming and lemmatization, I thought of a tool that can be used to help edit a first draft. Specifically, this tool would use stemming and lemmatization to quickly find repetitions in text (not including stop words). The tool would be used from the command line, and works as follows:\n",
    "1. run the python script\n",
    "2. after the prompt, copy paste the text you want to edit\n",
    "3. press enter and get the count of repeated words.\n",
    "\n",
    "The script for the tool in included below. I used to paragraph above as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy paste paragraph: \n",
      "--------------------- \n",
      " The best strategy to increase writing speed while maintaining quality is twofold: Write a bad first draft, and do so as quickly as possible - do not overthink and worry about writing quality. Be ruthless in editing what you just wrote. After completing this NLP project and learning and stemming and lemmatization, I thought of a tool that can be used to help edit a first draft. Specifically, this tool would use stemming and lemmatization to quickly find repetitions in text (not including stop words). The tool would be used from the command line, and works as follows: run the python script after the prompt, copy paste the text you want to edit press enter and find the repeated words.\n",
      "--------------------- \n",
      "\n",
      "Porter stem: \n",
      "\n",
      "write 3\n",
      "qualiti 2\n",
      "first 2\n",
      "draft 2\n",
      "do 2\n",
      "quickli 2\n",
      "edit 3\n",
      "you 2\n",
      "after 2\n",
      "stem 2\n",
      "lemmat 2\n",
      "tool 3\n",
      "use 3\n",
      "would 2\n",
      "find 2\n",
      "text 2\n",
      "\n",
      "\n",
      "Lancaster stem:\n",
      "\n",
      "writ 3\n",
      "qual 2\n",
      "first 2\n",
      "draft 2\n",
      "do 2\n",
      "quick 2\n",
      "edit 3\n",
      "you 2\n",
      "aft 2\n",
      "stem 2\n",
      "lem 2\n",
      "tool 3\n",
      "us 3\n",
      "would 2\n",
      "find 2\n",
      "text 2\n",
      "\n",
      "\n",
      "Wornet lem:\n",
      "\n",
      "writing 2\n",
      "quality 2\n",
      "first 2\n",
      "draft 2\n",
      "do 2\n",
      "quickly 2\n",
      "you 2\n",
      "after 2\n",
      "stemming 2\n",
      "lemmatization 2\n",
      "tool 3\n",
      "used 2\n",
      "edit 2\n",
      "would 2\n",
      "find 2\n",
      "text 2\n"
     ]
    }
   ],
   "source": [
    "import nltk, re, string\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# user inputs paragraph\n",
    "pargraph_str = input('Copy paste paragraph: \\n--------------------- \\n ')\n",
    "pargraph_str = pargraph_str.lower()\n",
    "\n",
    "# removes punctuation and creates list of words\n",
    "pargraph_str = pargraph_str.replace(',', ' ')\n",
    "pargraph_str = pargraph_str.replace('.', ' ')\n",
    "pargraph_str = pargraph_str.replace(\"'\", '')\n",
    "pargraph_str_split = pargraph_str.split()\n",
    "\n",
    "# list of stop words to ignore, can add to this list\n",
    "stop_words = ['a','the','and','this','of','is','to','as','in','by','an','into','it','be','on','that','at']\n",
    "\n",
    "# removes stopwords from list\n",
    "new_words = [word for word in pargraph_str_split if (word not in stop_words) \n",
    "and (word.isdigit()==False) # to remove digits\n",
    "and (word != '=') # to remove equations\n",
    "and ('(' not in word)] # to remove citations\n",
    "\n",
    "# stemmers\n",
    "ps = PorterStemmer()\n",
    "lan = LancasterStemmer()\n",
    "\n",
    "# lemmatizer\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "# empty lists\n",
    "new_lst_stem = []\n",
    "new_lst_lem = []\n",
    "new_lst_lan = []\n",
    "\n",
    "# creates list with only stem words\n",
    "for i in new_words:\n",
    "    new_lst_stem.append(ps.stem(i))\n",
    "\n",
    "for i in new_words:\n",
    "    new_lst_lem.append(lm.lemmatize(i))\n",
    "\n",
    "for i in new_words:\n",
    "    new_lst_lan.append(lan.stem(i))\n",
    "\n",
    "#counter\n",
    "counter_stem = dict(Counter(new_lst_stem))\n",
    "counter_lem = dict(Counter(new_lst_lem))\n",
    "counter_lan = dict(Counter(new_lst_lan))\n",
    "\n",
    "# remove when value of dict/counter is equal to 1\n",
    "new_dict_stem = {key:val for key, val in counter_stem.items() if val != 1}\n",
    "new_dict_lem = {key:val for key, val in counter_lem.items() if val != 1}\n",
    "new_dict_lan = {key:val for key, val in counter_lan.items() if val != 1}\n",
    "\n",
    "# output\n",
    "if (bool(new_dict_stem)==False) and (bool(new_dict_lem)==False) and (bool(new_dict_lan)==False):\n",
    "\tprint('\\n No repetitions found') # prints in case no repetitions found\n",
    "else:\n",
    "    print('--------------------- \\n')\n",
    "    print('Porter stem: \\n')\n",
    "    for k,v in new_dict_stem.items():\n",
    "        print(k,v)\n",
    "    print('\\n')\n",
    "    print('Lancaster stem:\\n')\n",
    "    for k,v in new_dict_lan.items():\n",
    "        print(k,v)\n",
    "    print('\\n')\n",
    "    print('Wornet lem:\\n')\n",
    "    for k,v in new_dict_lem.items():\n",
    "        print(k,v)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now use the information above to rewrite the last paragraph and reduce the number of repetitions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix - Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPERIMENT 1: Testing different vector sizes\n",
      "N = 3\n",
      "Accuracy 83.3% (data items: 15158, correct: 12622)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "Accuracy 83.3% (data items: 15158, correct: 12622)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "Accuracy 83.3% (data items: 15158, correct: 12622)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "N = 30\n",
      "Accuracy 85.9% (data items: 15158, correct: 13026)\n",
      "Accuracy 85.1% (data items: 1734, correct: 1476)\n",
      "Accuracy 83.3% (data items: 15158, correct: 12622)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "Accuracy 83.3% (data items: 15158, correct: 12622)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "N = 300\n",
      "Accuracy 100.0% (data items: 15158, correct: 15158)\n",
      "Accuracy 92.7% (data items: 1734, correct: 1608)\n",
      "Accuracy 86.6% (data items: 15158, correct: 13130)\n",
      "Accuracy 85.5% (data items: 1734, correct: 1482)\n",
      "Accuracy 83.3% (data items: 15158, correct: 12622)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "N = 3000\n",
      "Accuracy 100.0% (data items: 15158, correct: 15158)\n",
      "Accuracy 97.2% (data items: 1734, correct: 1686)\n",
      "Accuracy 98.7% (data items: 15158, correct: 14954)\n",
      "Accuracy 95.8% (data items: 1734, correct: 1662)\n",
      "Accuracy 83.3% (data items: 15158, correct: 12622)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "\n",
      "EXPERIMENT 2: Testing different data types\n",
      "Path = lingspam_public/bare\n",
      "Accuracy 100.0% (data items: 17036, correct: 17036)\n",
      "Accuracy 96.9% (data items: 1734, correct: 1680)\n",
      "Accuracy 98.7% (data items: 17036, correct: 16813)\n",
      "Accuracy 95.8% (data items: 1734, correct: 1662)\n",
      "Accuracy 83.3% (data items: 17036, correct: 14195)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "Path = lingspam_public/stop\n",
      "Accuracy 100.0% (data items: 15633, correct: 15633)\n",
      "Accuracy 96.9% (data items: 1734, correct: 1680)\n",
      "Accuracy 98.5% (data items: 15633, correct: 15403)\n",
      "Accuracy 96.2% (data items: 1734, correct: 1668)\n",
      "Accuracy 83.1% (data items: 15633, correct: 12994)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "Path = lingspam_public/lemm\n",
      "Accuracy 100.0% (data items: 15635, correct: 15635)\n",
      "Accuracy 97.6% (data items: 1734, correct: 1692)\n",
      "Accuracy 98.8% (data items: 15635, correct: 15455)\n",
      "Accuracy 96.2% (data items: 1734, correct: 1668)\n",
      "Accuracy 83.4% (data items: 15635, correct: 13037)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n",
      "Path = lingspam_public/lemm_stop\n",
      "Accuracy 100.0% (data items: 15672, correct: 15672)\n",
      "Accuracy 97.9% (data items: 1734, correct: 1698)\n",
      "Accuracy 98.8% (data items: 15672, correct: 15480)\n",
      "Accuracy 95.5% (data items: 1734, correct: 1656)\n",
      "Accuracy 83.4% (data items: 15672, correct: 13074)\n",
      "Accuracy 83.4% (data items: 1734, correct: 1446)\n"
     ]
    }
   ],
   "source": [
    "folder = 'lingspam_public/bare'\n",
    "N = numpy.array([3,30,300,3000]) \n",
    "print('\\nEXPERIMENT 1: Testing different vector sizes')\n",
    "results = []\n",
    "for n in N:\n",
    "    print('N = {}'.format(n))\n",
    "    A = trainTestFolder(folder,n)\n",
    "    results.append(A)\n",
    "    \n",
    "n = 3000\n",
    "typeFolders = ['lingspam_public/bare','lingspam_public/stop','lingspam_public/lemm','lingspam_public/lemm_stop']\n",
    "print('\\nEXPERIMENT 2: Testing different data types')\n",
    "for folder in typeFolders:\n",
    "    print('Path = {}'.format(folder))\n",
    "    B = trainTestFolder(folder,n)\n",
    "    results.append(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
